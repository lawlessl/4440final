{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74fbafcd-f735-44dc-a79a-db678e3d9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b8b44f-dec5-4ddb-8640-d99a2d6f90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         job_bullets            job_role  \\\n",
      "0  ['Conducted surveys and focus groups to gather...     User Researcher   \n",
      "1  ['Developed and conducted surveys to assess us...     User Researcher   \n",
      "2  ['Assisted in the design and execution of in-d...     User Researcher   \n",
      "3  ['Managed and maintained office facilities, in...  Facilities Manager   \n",
      "4  ['Developed and executed space planning strate...  Facilities Manager   \n",
      "\n",
      "                                     job_description  \\\n",
      "0  Conduct user research to understand customer n...   \n",
      "1  Conduct user research to understand customer n...   \n",
      "2  Conduct user research to understand customer n...   \n",
      "3  Facilities Managers manage facilities and buil...   \n",
      "4  Facilities Managers manage facilities and buil...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  User research methods Usability testing Data a...   \n",
      "1  User research methods Usability testing Data a...   \n",
      "2  User research methods Usability testing Data a...   \n",
      "3  Facilities management Property maintenance Spa...   \n",
      "4  Facilities management Property maintenance Spa...   \n",
      "\n",
      "                                    responsibilities     applicant_job_role  \\\n",
      "0  Conduct user research to understand user behav...      Market Researcher   \n",
      "1  Conduct user research to understand user behav...  Research Psychologist   \n",
      "2  Conduct user research to understand user behav...      Senior Researcher   \n",
      "3  Manage office facilities, including maintenanc...             QA Manager   \n",
      "4  Manage office facilities, including maintenanc...      Logistics Manager   \n",
      "\n",
      "                                    applicant_skills  \n",
      "0  Market research tools and techniques User inte...  \n",
      "1  Research methodology Usability testing with in...  \n",
      "2  Social science research methods User testing S...  \n",
      "3  Construction management Estate planning Enviro...  \n",
      "4  Project management Server maintenance Site pla...  \n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"resume_dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2324199b-f569-44a8-adc0-a145c54bcb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd8b076-0d82-463d-96bf-d1c4cda86c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "class ResumeFitDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Build Job Description (Query)\n",
    "        jd_text = f\"{row['job_role']}. {row['job_description']} \" \\\n",
    "                  f\"\\n\\nSkills: {row['skills']}.\" \\\n",
    "                  f\"\\nResponsibilities: {row['responsibilities']}\"\n",
    "\n",
    "        # Parse and build Resume (Key) with realistic formatting\n",
    "        job_bullets = row[\"job_bullets\"]\n",
    "        if isinstance(job_bullets, str):\n",
    "            try:\n",
    "                job_bullets = ast.literal_eval(job_bullets)\n",
    "            except:\n",
    "                job_bullets = []\n",
    "\n",
    "        resume_text = f\"{row['applicant_job_role']}\\n\" + \\\n",
    "                      (\"\\n- \" + \"\\n- \".join(job_bullets) if job_bullets else \"\") + \\\n",
    "                      f\"\\n\\nSkills: {row['applicant_skills']}\"\n",
    "\n",
    "        # Tokenize input pair (query, key)\n",
    "        encoding = self.tokenizer(\n",
    "            jd_text,\n",
    "            resume_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            # \"label\": torch.tensor(float(row[\"suitability_score\"]), dtype=torch.float)\n",
    "            \"label\": torch.tensor(0.0, dtype=torch.float)  # placeholder for now\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8d9343-52ba-4adc-8770-85465cd2ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the dataset\n",
    "dataset = ResumeFitDataset(df, tokenizer)\n",
    "sample = dataset[0]\n",
    "print(sample[\"label\"])  # should print something like 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8f2379-5c3a-4e81-b9cb-29c4541aa6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataloader with proper train test splits\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = ResumeFitDataset(train_df, tokenizer)\n",
    "test_dataset = ResumeFitDataset(test_df, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2464821a-5e13-45d8-98a9-8cca5cb136dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "class JobFitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JobFitModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # Grab [CLS] token\n",
    "        score = self.ffn(cls_embedding)\n",
    "        return score.squeeze(1)  # Return shape: (batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5db9a2-ad34-4542-8b59-911b76b51fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, epochs=3):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} training loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54d6197c-059b-4c60-b50e-454ce794c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test MSE Loss: {avg_loss:.4f}\")\n",
    "    return all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c60bf835-19e7-4262-ac19-428f1bb39646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(preds, labels):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(labels, preds, alpha=0.5, color='blue')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red')  # ideal diagonal\n",
    "    plt.xlabel(\"True Suitability Score\")\n",
    "    plt.ylabel(\"Predicted Score\")\n",
    "    plt.title(\"Predicted vs. True Suitability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b5d428-6816-4d87-8595-94de31ed1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_suitability(model, tokenizer, jd_text, resume_text, device):\n",
    "    model.eval()\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        jd_text, resume_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aff740c-8d05-46e2-b2ae-877569aee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "model = JobFitModel()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b7e5b-80a6-407d-a22a-448924d2d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "train_model(model, train_loader, optimizer, criterion, device, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580a00-c320-49f5-800f-8d28e55ba2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "preds, labels = evaluate_model(model, test_loader, criterion, device)\n",
    "plot_predictions(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96efdd-e8b4-4447-9261-c9461a3bf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "jd_text = \"UX Researcher. Conduct user research to inform product design. Skills: Interviewing, Data Analysis. Responsibilities: Design studies, synthesize insights.\"\n",
    "resume_text = \"\"\"UX Specialist\n",
    "- Conducted 30+ user interviews\n",
    "- Analyzed feedback to drive design decisions\n",
    "- Collaborated with product and design teams\n",
    "\n",
    "Skills: User Research, Journey Mapping, Usability Testing\"\"\"\n",
    "\n",
    "score = predict_suitability(model, tokenizer, jd_text, resume_text, device)\n",
    "print(f\"Predicted Suitability: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (resume-env)",
   "language": "python",
   "name": "resume-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
