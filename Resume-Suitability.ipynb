{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fbafcd-f735-44dc-a79a-db678e3d9e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanw\\4440final\\resume-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b8b44f-dec5-4ddb-8640-d99a2d6f90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Resume Job Role                                  Resume Experience  \\\n",
      "0      Market Researcher  ['Conducted surveys and focus groups to gather...   \n",
      "1  Research Psychologist  ['Developed and conducted surveys to assess us...   \n",
      "2      Senior Researcher  ['Assisted in the design and execution of in-d...   \n",
      "3             QA Manager  ['Managed and maintained office facilities, in...   \n",
      "4      Logistics Manager  ['Developed and executed space planning strate...   \n",
      "\n",
      "                                       Resume Skills           Job Title  \\\n",
      "0  Market research tools and techniques User inte...     User Researcher   \n",
      "1  Research methodology Usability testing with in...     User Researcher   \n",
      "2  Social science research methods User testing S...     User Researcher   \n",
      "3  Construction management Estate planning Enviro...  Facilities Manager   \n",
      "4  Project management Server maintenance Site pla...  Facilities Manager   \n",
      "\n",
      "                                     Job Description  \\\n",
      "0  Conduct user research to understand customer n...   \n",
      "1  Conduct user research to understand customer n...   \n",
      "2  Conduct user research to understand customer n...   \n",
      "3  Facilities Managers manage facilities and buil...   \n",
      "4  Facilities Managers manage facilities and buil...   \n",
      "\n",
      "                                          Job Skills  \\\n",
      "0  User research methods Usability testing Data a...   \n",
      "1  User research methods Usability testing Data a...   \n",
      "2  User research methods Usability testing Data a...   \n",
      "3  Facilities management Property maintenance Spa...   \n",
      "4  Facilities management Property maintenance Spa...   \n",
      "\n",
      "                                Job Responsibilities  Job Title Match  \\\n",
      "0  Conduct user research to understand user behav...         0.609490   \n",
      "1  Conduct user research to understand user behav...         0.511444   \n",
      "2  Conduct user research to understand user behav...         0.617142   \n",
      "3  Manage office facilities, including maintenanc...         0.604425   \n",
      "4  Manage office facilities, including maintenanc...         0.648784   \n",
      "\n",
      "   Skills Match  Responsibilities Match  \n",
      "0      0.633559                0.571394  \n",
      "1      0.785575                0.590450  \n",
      "2      0.676319                0.556635  \n",
      "3      0.591372                0.766494  \n",
      "4      0.723060                0.770966  \n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"final_resume_dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2324199b-f569-44a8-adc0-a145c54bcb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd8b076-0d82-463d-96bf-d1c4cda86c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldPairDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, field_1, field_2, label_field, max_len=512, combine_fields=None):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.field_1 = field_1\n",
    "        self.field_2 = field_2\n",
    "        self.label_field = label_field\n",
    "        self.max_len = max_len\n",
    "        self.combine_fields = combine_fields  # optional tuple of fields to join\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Support concatenating multiple fields into input_a\n",
    "        if self.combine_fields:\n",
    "            input_a = \" \".join(str(row[f]) for f in self.combine_fields)\n",
    "        else:\n",
    "            input_a = str(row[self.field_1])\n",
    "\n",
    "        input_b = str(row[self.field_2])\n",
    "        label = float(row[self.label_field])\n",
    "\n",
    "        # Pretty-print list fields like Resume Experience\n",
    "        try:\n",
    "            if input_b.startswith(\"[\") and isinstance(eval(input_b), list):\n",
    "                input_b = \"\\n- \" + \"\\n- \".join(ast.literal_eval(input_b))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            input_a,\n",
    "            input_b,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8d9343-52ba-4adc-8770-85465cd2ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the dataset\n",
    "# Title Match\n",
    "title_dataset = FieldPairDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    field_1=\"Job Title\",\n",
    "    field_2=\"Resume Job Role\",\n",
    "    label_field=\"Job Title Match\"\n",
    ")\n",
    "\n",
    "# Skills Match\n",
    "skills_dataset = FieldPairDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    field_1=\"Job Skills\",\n",
    "    field_2=\"Resume Skills\",\n",
    "    label_field=\"Skills Match\"\n",
    ")\n",
    "\n",
    "# Responsibilities Match (combining Job Description + Responsibilities)\n",
    "responsibilities_dataset = FieldPairDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    field_1=None,\n",
    "    field_2=\"Resume Experience\",\n",
    "    label_field=\"Responsibilities Match\",\n",
    "    combine_fields=(\"Job Description\", \"Job Responsibilities\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8f2379-5c3a-4e81-b9cb-29c4541aa6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataloader with proper train test splits\n",
    "# df = df.sample(frac=0.1, random_state=42)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Title Match\n",
    "title_train_dataset = FieldPairDataset(train_df, tokenizer,\n",
    "    field_1=\"Job Title\", field_2=\"Resume Job Role\", label_field=\"Job Title Match\")\n",
    "\n",
    "title_test_dataset = FieldPairDataset(test_df, tokenizer,\n",
    "    field_1=\"Job Title\", field_2=\"Resume Job Role\", label_field=\"Job Title Match\")\n",
    "\n",
    "title_train_loader = DataLoader(title_train_dataset, batch_size=8, shuffle=True)\n",
    "title_test_loader = DataLoader(title_test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Skills Match\n",
    "skills_train_dataset = FieldPairDataset(train_df, tokenizer,\n",
    "    field_1=\"Job Skills\", field_2=\"Resume Skills\", label_field=\"Skills Match\")\n",
    "\n",
    "skills_test_dataset = FieldPairDataset(test_df, tokenizer,\n",
    "    field_1=\"Job Skills\", field_2=\"Resume Skills\", label_field=\"Skills Match\")\n",
    "\n",
    "skills_train_loader = DataLoader(skills_train_dataset, batch_size=8, shuffle=True)\n",
    "skills_test_loader = DataLoader(skills_test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Responsibilities Match\n",
    "resp_train_dataset = FieldPairDataset(train_df, tokenizer,\n",
    "    field_1=None, field_2=\"Resume Experience\", label_field=\"Responsibilities Match\",\n",
    "    combine_fields=(\"Job Description\", \"Job Responsibilities\"))\n",
    "\n",
    "resp_test_dataset = FieldPairDataset(test_df, tokenizer,\n",
    "    field_1=None, field_2=\"Resume Experience\", label_field=\"Responsibilities Match\",\n",
    "    combine_fields=(\"Job Description\", \"Job Responsibilities\"))\n",
    "\n",
    "resp_train_loader = DataLoader(resp_train_dataset, batch_size=8, shuffle=True)\n",
    "resp_test_loader = DataLoader(resp_test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2464821a-5e13-45d8-98a9-8cca5cb136dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "class JobFitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JobFitModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # Grab [CLS] token\n",
    "        score = self.ffn(cls_embedding)\n",
    "        return score.squeeze(1)  # Return shape: (batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5db9a2-ad34-4542-8b59-911b76b51fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, epochs=3):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} training loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d6197c-059b-4c60-b50e-454ce794c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test MSE Loss: {avg_loss:.4f}\")\n",
    "    return all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60bf835-19e7-4262-ac19-428f1bb39646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(preds, labels):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(labels, preds, alpha=0.5, color='blue')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red')  # ideal diagonal\n",
    "    plt.xlabel(\"True Suitability Score\")\n",
    "    plt.ylabel(\"Predicted Score\")\n",
    "    plt.title(\"Predicted vs. True Suitability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b5d428-6816-4d87-8595-94de31ed1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_suitability(model, tokenizer, jd_text, resume_text, device):\n",
    "    model.eval()\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        jd_text, resume_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aff740c-8d05-46e2-b2ae-877569aee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87ba40dc-c666-4524-8923-c66cb9023013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup all models\n",
    "title_model = JobFitModel().to(device)\n",
    "title_optimizer = torch.optim.AdamW(title_model.parameters(), lr=2e-5)\n",
    "title_criterion = nn.MSELoss()\n",
    "\n",
    "skills_model = JobFitModel().to(device)\n",
    "skills_optimizer = torch.optim.AdamW(skills_model.parameters(), lr=2e-5)\n",
    "skills_criterion = nn.MSELoss()\n",
    "\n",
    "resp_model = JobFitModel().to(device)\n",
    "resp_optimizer = torch.optim.AdamW(resp_model.parameters(), lr=2e-5)\n",
    "resp_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca18a71-05a1-4251-8d34-8e5efbc612a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|â–Ž                                                         | 2/424 [00:55<3:16:00, 27.87s/it, loss=0.0594]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train title match model\n",
    "train_model(title_model, title_train_loader, title_optimizer, title_criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7e588-cdb0-4c70-8b52-c5019d0a936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train skills match model\n",
    "train_model(skills_model, skills_train_loader, skills_optimizer, skills_criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd11ff-e3d3-4294-aec0-5ea25318a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train responsibilities match model\n",
    "train_model(resp_model, resp_train_loader, resp_optimizer, resp_criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580a00-c320-49f5-800f-8d28e55ba2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "# Evaluate Title Match\n",
    "title_preds, title_labels = evaluate_model(title_model, title_test_loader, title_criterion, device)\n",
    "plot_predictions(title_preds, title_labels)\n",
    "\n",
    "# Evaluate Skills Match\n",
    "skills_preds, skills_labels = evaluate_model(skills_model, skills_test_loader, skills_criterion, device)\n",
    "plot_predictions(skills_preds, skills_labels)\n",
    "\n",
    "# Evaluate Responsibilities Match\n",
    "resp_preds, resp_labels = evaluate_model(resp_model, resp_test_loader, resp_criterion, device)\n",
    "plot_predictions(resp_preds, resp_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96efdd-e8b4-4447-9261-c9461a3bf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "# Job Posting Fields\n",
    "job_title = \"User Researcher\"\n",
    "job_skills = \"User research methods, usability testing, data analysis\"\n",
    "job_responsibilities = \"Conduct interviews and usability studies. Synthesize user insights.\"\n",
    "\n",
    "# Resume Fields\n",
    "resume_role = \"Market Researcher\"\n",
    "resume_skills = \"Qualitative research, A/B testing, surveys\"\n",
    "resume_experience = \"- Conducted focus groups\\n- Analyzed survey data\\n- Presented user insights\"\n",
    "\n",
    "# Title Match Prediction\n",
    "title_score = predict_suitability(\n",
    "    title_model,\n",
    "    tokenizer,\n",
    "    jd_text=job_title,\n",
    "    resume_text=resume_role,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Skills Match Prediction\n",
    "skills_score = predict_suitability(\n",
    "    skills_model,\n",
    "    tokenizer,\n",
    "    jd_text=job_skills,\n",
    "    resume_text=resume_skills,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Responsibilities Match Prediction\n",
    "responsibilities_input = job_responsibilities + \" \" + job_title\n",
    "resp_score = predict_suitability(\n",
    "    resp_model,\n",
    "    tokenizer,\n",
    "    jd_text=responsibilities_input,\n",
    "    resume_text=resume_experience,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Title Match Score:           {title_score:.3f}\")\n",
    "print(f\"Skills Match Score:          {skills_score:.3f}\")\n",
    "print(f\"Responsibilities Match Score:{resp_score:.3f}\")\n",
    "\n",
    "overall_score = (title_score + skills_score + resp_score) / 3\n",
    "print(f\"\\nOverall Predicted Suitability: {overall_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (resume-env)",
   "language": "python",
   "name": "resume-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
